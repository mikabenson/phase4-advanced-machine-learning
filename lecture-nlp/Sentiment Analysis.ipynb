{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Project\n",
    "### 1. Introduction\n",
    "Sentiment analysis is a natural language processing (NLP) task that involves determining the sentiment expressed in a piece of text, such as whether it is positive, negative, or neutral. This application is widely used in industries to analyze customer feedback, reviews, social media posts, and much more. For example, businesses use sentiment analysis to gauge customer satisfaction or identify negative feedback for timely action.\n",
    "\n",
    "The purpose of this project is to walk through the essential stages of implementing sentiment analysis using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import Necessary Libraries\n",
    "# These libraries are required for data handling, preprocessing, feature extraction, and modeling.\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # extracts importance of word in a text\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords') # downloads a list of common stop words\n",
    "nltk.download('wordnet')  # large lexical database for english that groups words into set of synonyms\n",
    "                          # wordnet shows the relationship between words ... synonyms\n",
    "                          # wordnet is commonly used in lemmatization reducing words to their base form\n",
    "                          \n",
    "nltk.download('punkt_tab') # for tokenization splits text into sentences \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'few', 'some', 'very', 'm', 'in', \"weren't\", 'below', 'wasn', 'those', 'these', 'we', 'to', 'be', 'through', 'should', \"shouldn't\", 'with', 'on', 'me', 'any', 'before', 'him', 'same', 'them', 'by', 'about', \"you'd\", 'and', 've', 'herself', \"haven't\", 'being', 'was', \"doesn't\", \"didn't\", 'aren', 'an', 'haven', 'your', 'nor', 'up', 'if', 'just', 'd', \"you've\", 'hers', 'over', 'my', 'not', 'themselves', 'all', 'into', 'their', \"couldn't\", 'hadn', 'each', 'during', 'than', 'who', 'are', 'because', \"should've\", \"wasn't\", 'has', 'll', 'a', 'having', 'only', 'they', 'after', 'the', 'o', 's', \"won't\", 'she', 'so', 'have', 'mightn', 'again', 'out', 'hasn', 'other', 'where', \"you'll\", 'can', 'isn', \"shan't\", 'such', \"hadn't\", 're', 't', 'once', 'shan', 'didn', \"it's\", 'been', 'how', \"hasn't\", 'were', 'needn', 'our', 'his', 'above', 'why', 'her', 'against', 'further', 'couldn', 'you', \"aren't\", 'of', \"needn't\", 'had', 'wouldn', 'ours', 'weren', 'or', 'what', 'own', 'its', \"don't\", 'at', 'here', 'yourself', 'itself', \"she's\", 'doesn', \"mustn't\", 'yourselves', 'for', 'between', 'does', 'now', 'no', 'while', 'from', 'am', 'yours', 'himself', 'will', 'mustn', 'shouldn', 'it', \"you're\", 'did', 'this', 'more', 'won', \"isn't\", 'myself', 'when', 'until', 'as', 'under', 'theirs', 'both', 'ain', 'down', 'whom', 'doing', 'ma', 'there', 'too', 'y', 'that', \"wouldn't\", 'he', \"that'll\", 'but', 'then', 'don', \"mightn't\", 'off', 'which', 'i', 'do', 'most', 'ourselves', 'is'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "# tokens = ['this', 'is', 'a', 'sample', 'text']\n",
    "# filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "# print(filtered_tokens)  # Output: ['sample', 'text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded NLTK resources are essential for text preprocessing in sentiment analysis. The stopwords dataset contains common words like 'the' and 'and' which are removed to reduce noise and focus on meaningful content. wordnet is a lexical database used with the WordNetLemmatizer to normalize words by converting them to their root forms, ensuring consistency (e.g., \"running\" → \"run\"). The punkt tokenizer helps split text into sentences or words, enabling token-level operations like removing stopwords and extracting features. These resources streamline preprocessing, making raw text structured and ready for machine learning models, ensuring accurate and efficient analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordnet used with WordNetLemmatizer normalizes words converting them into their root forms ensuring consistency\n",
    "\n",
    "# punkt_tab helps splits the text into sentences or words for tokenization by removing stop words and extracting features\n",
    "\n",
    "# for lemmatization and tokenization streamlines the preprocessing by making the unstructured data into structured data ready for machine learning \n",
    "# algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           label                                               text\n",
      "924441  positive                is sometimes pleasantly surprised. \n",
      "924442  positive  You can smile  and pretend to be happy but wha...\n",
      "924443  positive  Happy Mothers Day to my Mom in Plaster Rock, N...\n",
      "924444  positive                    Alicias Overrr  on mothaas day!\n",
      "924445  positive                  @brownowl100 You in Asia too?  xx\n",
      "924446  positive                        im try for add friends btw \n",
      "924447  positive  Wow, I really don't have a clue how to use thi...\n",
      "924448  positive  @BKLYN_BBACH lol it makes u a great son for tr...\n",
      "924449  positive  contemplating dying my hair a lighter shade of...\n",
      "924450  positive  My wife told me she has a voice crush on Ryan ...\n",
      "924451  positive      here's to hoping Arsenal don't lose tonight! \n",
      "924452  positive  Happy Mothers Day! My mom is like asleep becau...\n",
      "924453  positive  Happy mother's day @reneeoshields and welcome ...\n",
      "924454  positive  Happy Mother's Day to all my fellow moms out t...\n",
      "924455  positive  @AndyCallaghan Hey mate! Thanks very much. Too...\n",
      "924456  positive  Omgz. I rode a train yesterday!  it was intere...\n",
      "924457  positive  @GiangcK: hï¿½, ?? coi nhï¿½m cï¿½ s?ng sï¿½t ...\n",
      "924458  positive  Happy Mother's Day Muuuum! Now I am off to Cam...\n",
      "924459  positive  @BARBEQT: awww, you're welcome, mama.  thank y...\n",
      "924460  positive              My mommy liked her mother's day gift \n",
      "924461  positive            good party last night!! im glad i went \n",
      "924462  positive  @nikkig8783 wouldn't even cross my mind to put...\n",
      "924463  positive          Happy mothers day  . I love you mum &lt;3\n",
      "924464  positive                               Im juSt cruisinG... \n",
      "924465  positive  A Happy Mother's Day to all moms!  About to go...\n",
      "924466  positive  cartoon: Making A Career In A Post-2.0-World h...\n",
      "924467  positive  &quot;The maker of the stars would rather die ...\n",
      "924468  positive  Just got done cleaning house, phone with Micha...\n",
      "924469  positive  @meyerweb Was wondering... Imagine if someone ...\n",
      "924470  positive  @acmorawski damai, like the condo. like damai ...\n",
      "924471  positive                GIRLFRIEND GETS HOME IN AN HOUR!!! \n",
      "924472  positive  @jason_mraz Welcome home, guys. Enjoy your muc...\n",
      "924473  positive   @PurpleMonsterrr Oh I'm just hanging out, on IM \n",
      "924474  positive                                 just slept again. \n",
      "924475  positive  @ChesterBe Do you like to watch cartoons with ...\n",
      "924476  positive  @ixxnay lol you're really the house cook! let ...\n",
      "924477  positive  Happy Mothers Day boo!  tell your momma for me...\n",
      "924478  positive          @kittydisco until when are your classes? \n",
      "924479  positive  yeaaa!!!! Ado The Hague won with soccer  sow n...\n",
      "924480  positive  Trying to figure out iMovie.  I have a sneakin...\n",
      "924481  positive             @KatJB Nicee.!  Yes they are very Cool\n",
      "924482  positive  @EdenSpodek luckily their thoughtful father is...\n",
      "924483  positive  @LacyKarr I don't think anyone's died from a t...\n",
      "924484  positive  OMG 2moz Before Skool Im Going To That Cafe To...\n",
      "924485  positive             @HappyHealthyPup that is a GREAT idea \n",
      "924486  positive              And some interesting friends as well \n",
      "924487  positive  @Jamiebower hope you're having a great day &am...\n",
      "924488  positive  @flashvipe  dont worry, we can talk in english...\n",
      "924489  positive           @jeeyoonit the not-so-secret rape gang? \n",
      "924490  positive                                             @Hooty\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Load Dataset\n",
    "data = pd.read_csv(\"sentiment_dataset.csv.crdownload\")  # Replace with actual file path\n",
    "print(data.tail(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer() # initialize the lemmatizer\n",
    "    stop_words = set(stopwords.words('english')) # initialize the stop words\n",
    "    \n",
    "    text = text.lower() # set the lowercase on the text\n",
    "    \n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text) # replace the non_numeric characters but retain numbers( keep the alphabets, numbers and spaces)\n",
    "    \n",
    "    tokens = word_tokenize(text) # here we tokenize the text\n",
    "    \n",
    "    # remove the stop words\n",
    "    cleaned_tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # here lemmatize the tokens\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in cleaned_tokens]\n",
    "    \n",
    "    return ' '.join(lemmatized_tokens)  # here we return the processed text as a string ready for input on the machine learning algorithms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_text(text):\n",
    "#     # Initialize lemmatizer and stop words\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "#     # Lowercase the text\n",
    "#     text = text.lower()\n",
    "    \n",
    "#     # Replace non-alphanumeric characters, but retain numbers\n",
    "#     text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)  # Keep alphabets, numbers, and spaces only\n",
    "    \n",
    "#     # Tokenize the text\n",
    "#     tokens = word_tokenize(text)\n",
    "    \n",
    "#     # Remove stopwords\n",
    "#     cleaned_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "#     # lemmatize tokens\n",
    "#     lemmatized_tokens = [lemmatizer.lemmatize(word) for word in cleaned_tokens]\n",
    "    \n",
    "#     # Return the processed text as a single string\n",
    "#     return ' '.join(lemmatized_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direction taking link bit confusing 50'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(\"The directions for taking out a link are a bit confusing, and $50 I have\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step in preprocessing is converting the entire text to lowercase ensuring the model treats words\n",
    "\n",
    "# step two: removing non_alphanumeric characters including punctuation, using regular expression which focuses on meaningful content while \n",
    "# retaining numbers for context.\n",
    "\n",
    "# Tokenizer(text) into individual words using word_tokenizer which allows for granular manipulation\n",
    "\n",
    "# Lemmatization is then applied to each token using WordNetLemmatizer() which converts words into their root forms  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `preprocess_text` function is a comprehensive text-cleaning utility essential for preparing raw text data in sentiment analysis tasks. Initially, it initializes two key components: a lemmatizer from NLTK’s `WordNetLemmatizer` and a set of English stopwords from NLTK. The first step in preprocessing is converting the entire text to lowercase, ensuring that the model treats words like \"Apple\" and \"apple\" equally. Next, the function removes non-alphanumeric characters, including punctuation, using regular expressions, which helps to focus on meaningful content while retaining numbers for context. The text is then tokenized into individual words using NLTK’s `word_tokenize`, allowing for granular manipulation. Stopwords—commonly used words that don’t add significant meaning—are filtered out to reduce noise and enhance the model’s ability to identify relevant words. Following this, lemmatization is applied to each token using the `WordNetLemmatizer`, which converts words to their root forms (e.g., \"running\" becomes \"run\"), standardizing variations. Finally, the processed tokens are reassembled into a single string, ready for input into machine learning models. This function plays a pivotal role in transforming raw, unstructured text into a clean and meaningful format that improves model performance and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  negative  is upset that he can't update his Facebook by ...\n",
       "1  negative  @Kenichan I dived many times for the ball. Man...\n",
       "2  negative    my whole body feels itchy and like its on fire \n",
       "3  negative  @nationwideclass no, it's not behaving at all....\n",
       "4  negative                      @Kwesidei not the whole crew "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the function preprocess_text transforms the raw, unstructured text into clean and meaningful format that improves the models performance\n",
    "\n",
    "data = data.dropna() # lets drop the null values in the data set\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets apply the preprocessing to the dataset..\n",
    "data['label'] = data['label'].map({'negative': 0, 'positive': 1}) # map the negative and positive labels with 0 and 1 respectively\n",
    "data['text'] = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Apply preprocessing to the dataset\n",
    "# data = data.dropna()\n",
    "# data['label'] = data['label'].map({'negative': 0, 'positive': 1})\n",
    "# data['text'] = data['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above drops null values from that data, then maps the values negative and positive to 0 and 1 respectively.\n",
    "\n",
    "The next line of code uses the fucntion we created abouve to preprocess our data, thus in the end we will have cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  negative  is upset that he can't update his Facebook by ...\n",
       "1  negative  @Kenichan I dived many times for the ball. Man...\n",
       "2  negative    my whole body feels itchy and like its on fire \n",
       "3  negative  @nationwideclass no, it's not behaving at all....\n",
       "4  negative                      @Kwesidei not the whole crew "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data Into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Split Dataset\n",
    "# Split into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['text'], data['label'], test_size=0.2, random_state=42, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we split our data into train and test data for model training and evaluation purposes. \n",
    "\n",
    "80% train data and 20% test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Build Pipeline\n",
    "# Create a pipeline to streamline feature extraction and model training.\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a pipepline, to streamline feature extraction and model training. TfidVectorizer as we had earlier discussed quantifies the weight of a token in a given text. (like stardadizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [1000, 3000, 5000],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],  # Unigrams or Unigrams + Bigrams\n",
    "    'model__C': [0.1, 1, 10],  # Regularization strength\n",
    "    'model__solver': ['liblinear', 'lbfgs'],  # Solver for Logistic Regression\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;model&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__C&#x27;: [0.1, 1, 10],\n",
       "                         &#x27;model__solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;],\n",
       "                         &#x27;tfidf__max_features&#x27;: [1000, 3000, 5000],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2)]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;model&#x27;, LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__C&#x27;: [0.1, 1, 10],\n",
       "                         &#x27;model__solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;],\n",
       "                         &#x27;tfidf__max_features&#x27;: [1000, 3000, 5000],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2)]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
       "                (&#x27;model&#x27;, LogisticRegression(C=10, solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_features=5000, ngram_range=(1, 2))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('model', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__C': [0.1, 1, 10],\n",
       "                         'model__solver': ['liblinear', 'lbfgs'],\n",
       "                         'tfidf__max_features': [1000, 3000, 5000],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2)]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__C': 10, 'model__solver': 'liblinear', 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2)}\n",
      "Best Cross-Validation Accuracy: 0.7709302900108985\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Output the best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.771528125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77    159494\n",
      "           1       0.76      0.80      0.78    160506\n",
      "\n",
      "    accuracy                           0.77    320000\n",
      "   macro avg       0.77      0.77      0.77    320000\n",
      "weighted avg       0.77      0.77      0.77    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on a test set\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "print(\"Test Set Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict Sentiment for Custom Reviews\n",
    "# Function to predict sentiment for a given review.\n",
    "def predict_sentiment(review):\n",
    "    review_preprocessed = preprocess_text(review)\n",
    "    prediction = grid_search.best_estimator_.predict([review_preprocessed])\n",
    "    return \"Positive\" if prediction[0] == 1 else \"Negative\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Negative\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example:\n",
    "review = \"Our president is overtaxing us, which is becoming so burdensome to many kenyans who are not employed\"\n",
    "\n",
    "print(\"Prediction:\", predict_sentiment(review))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
