{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll install the popular [XGBoost](http://xgboost.readthedocs.io/en/latest/index.html) library and explore how to use this popular boosting model to classify different types of wine using the [Wine Quality Dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality) from the UCI Machine Learning Dataset Repository.  \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Fit, tune, and evaluate an XGBoost algorithm\n",
    "\n",
    "## Installing XGBoost\n",
    "\n",
    "Run this lab on your local computer.\n",
    "\n",
    "The XGBoost model is not currently included in scikit-learn, so we'll have to install it on our own.  To install XGBoost, you'll need to use `pip`. \n",
    "\n",
    "To install XGBoost, follow these steps:\n",
    "\n",
    "1. Open up a new terminal window \n",
    "2. Activate your conda environment\n",
    "3. Run `pip install xgboost`\n",
    "4. Once the installation has completed, run the cell below to verify that everything worked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages (from xgboost) (1.22.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages (from xgboost) (1.10.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to import everything we'll need for this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "The dataset we'll be using for this lab is currently stored in the file `'winequality-red.csv'`.  \n",
    "\n",
    "In the cell below, use pandas to import the dataset into a dataframe, and inspect the `.head()` of the dataframe to ensure everything loaded correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fixed acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatile acidity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "citric acid",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "residual sugar",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chlorides",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "free sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total sulfur dioxide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "density",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sulphates",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alcohol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "quality",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b4c4bb86-4d57-4068-8e64-095d3fa77b3c",
       "rows": [
        [
         "0",
         "7.4",
         "0.7",
         "0.0",
         "1.9",
         "0.076",
         "11.0",
         "34.0",
         "0.9978",
         "3.51",
         "0.56",
         "9.4",
         "5"
        ],
        [
         "1",
         "7.8",
         "0.88",
         "0.0",
         "2.6",
         "0.098",
         "25.0",
         "67.0",
         "0.9968",
         "3.2",
         "0.68",
         "9.8",
         "5"
        ],
        [
         "2",
         "7.8",
         "0.76",
         "0.04",
         "2.3",
         "0.092",
         "15.0",
         "54.0",
         "0.997",
         "3.26",
         "0.65",
         "9.8",
         "5"
        ],
        [
         "3",
         "11.2",
         "0.28",
         "0.56",
         "1.9",
         "0.075",
         "17.0",
         "60.0",
         "0.998",
         "3.16",
         "0.58",
         "9.8",
         "6"
        ],
        [
         "4",
         "7.4",
         "0.7",
         "0.0",
         "1.9",
         "0.076",
         "11.0",
         "34.0",
         "0.9978",
         "3.51",
         "0.56",
         "9.4",
         "5"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/winequality-red.csv\")  # Move up one directory\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are dealing with a multiclass classification problem where we are predicting the quality of the wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, our target column will be `'quality'`.  That makes this a multiclass classification problem. Given the data in the columns from `'fixed_acidity'` through `'alcohol'`, we'll predict the quality of the wine.  \n",
    "\n",
    "This means that we need to store our target variable separately from the dataset, and then split the data and labels into training and test sets that we can use for cross-validation. \n",
    "\n",
    "### Splitting the Data\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "- Assign the `'quality'` column to `y` \n",
    "- Drop this column (`'quality'`) and assign the resulting DataFrame to `X` \n",
    "- Split the data into training and test sets. Set the `random_state` to 42   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"quality\"]\n",
    "X = df.drop(\"quality\", axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data\n",
    "\n",
    "These are the current target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "3      9\n",
       "4     40\n",
       "5    517\n",
       "6    469\n",
       "7    151\n",
       "8     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we check the target values on the quality\n",
    "y_train.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost requires that classification categories be integers that count up from 0, not starting at 3. Therefore you should instantiate a `LabelEncoder` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)) and convert both `y_train` and `y_test` into arrays containing label encoded values (i.e. integers that count up from 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2\n",
      "1       2\n",
      "2       4\n",
      "3       2\n",
      "4       3\n",
      "       ..\n",
      "1194    3\n",
      "1195    3\n",
      "1196    2\n",
      "1197    4\n",
      "1198    3\n",
      "Length: 1199, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# XGBoost requires that classification be integers that count from 0\n",
    "# convert the y tain and y test into arrays containing label encoded values which count from 0\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit and transform the training data\n",
    "y_train_le = pd.Series(le.fit_transform(y_train))\n",
    "\n",
    "y_test_le = pd.Series(le.transform(y_test))\n",
    "\n",
    "print(y_train_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the encoder\n",
    "# encoder = LabelEncoder()\n",
    "\n",
    "# # Fit and transform the training data\n",
    "# y_train = pd.Series(encoder.fit_transform(y_train))\n",
    "\n",
    "# # Transform the test data\n",
    "# y_test = pd.Series(encoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the new values start at 0 instead of 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      9\n",
       "1     40\n",
       "2    517\n",
       "3    469\n",
       "4    151\n",
       "5     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_le.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code here to inspect the values of y_train and y_test\n",
    "# y_train.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an XGBoost Model\n",
    "\n",
    "Now that you have prepared the data for modeling, you can use XGBoost to build a model that can accurately classify wine quality based on the features of the wine!\n",
    "\n",
    "The API for `xgboost` is purposefully written to mirror the same structure as other models in scikit-learn.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How XGBoost Works\n",
    "XGBoost works by iteratively adding models to correct the errors made by existing models. It builds a model in a stage-wise fashion and generalizes them by optimizing a loss function. The primary components of the XGBoost algorithm are:\n",
    "\n",
    "* Initialization: Start with an initial prediction, usually the mean of the target values.\n",
    "\n",
    "* Iterative Boosting: For each iteration:\n",
    "Compute the gradient (i.e., the difference between the predicted value and the actual value).\n",
    "Fit a base learner (e.g., a decision tree) to the gradient.\n",
    "Update the prediction by adding the learned base learner multiplied by a learning rate.\n",
    "\n",
    "* Regularization: Apply regularization to control model complexity and prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About XGBoost (extreme gradient boosting)\n",
    "\n",
    "Speed and Performance: XGBoost is designed to be efficient and can handle large datasets and high-dimensional data. It is known for its speed and performance improvements over other gradient boosting implementations.\n",
    "\n",
    "Regularization: It includes regularization parameters (L1 & L2) which helps to avoid overfitting.\n",
    "\n",
    "Parallelization: XGBoost supports parallel processing, making it faster than other gradient boosting implementations.\n",
    "\n",
    "Tree Pruning: XGBoost uses a technique called “pruning” (also known as “pre-pruning” or “maximum depth pruning”) to control the depth of the trees.\n",
    "\n",
    "Handling Missing Values: XGBoost has a built-in routine to handle missing values.\n",
    "\n",
    "Cross-Validation: It supports cross-validation at each iteration of the boosting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages (2.1.3)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages (from xgboost) (1.22.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Downloading xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/124.9 MB 1.4 MB/s eta 0:01:29\n",
      "   ---------------------------------------- 0.5/124.9 MB 1.4 MB/s eta 0:01:29\n",
      "   ---------------------------------------- 0.8/124.9 MB 799.2 kB/s eta 0:02:36\n",
      "   ---------------------------------------- 1.0/124.9 MB 883.6 kB/s eta 0:02:21\n",
      "   ---------------------------------------- 1.3/124.9 MB 958.5 kB/s eta 0:02:09\n",
      "    --------------------------------------- 1.6/124.9 MB 999.0 kB/s eta 0:02:04\n",
      "    --------------------------------------- 1.8/124.9 MB 1.0 MB/s eta 0:01:58\n",
      "    --------------------------------------- 2.1/124.9 MB 1.1 MB/s eta 0:01:54\n",
      "    --------------------------------------- 2.4/124.9 MB 1.1 MB/s eta 0:01:54\n",
      "    --------------------------------------- 2.4/124.9 MB 1.1 MB/s eta 0:01:54\n",
      "    --------------------------------------- 2.9/124.9 MB 1.1 MB/s eta 0:01:52\n",
      "    --------------------------------------- 2.9/124.9 MB 1.1 MB/s eta 0:01:52\n",
      "   - -------------------------------------- 3.1/124.9 MB 1.1 MB/s eta 0:01:53\n",
      "   - -------------------------------------- 3.4/124.9 MB 1.1 MB/s eta 0:01:50\n",
      "   - -------------------------------------- 3.7/124.9 MB 1.1 MB/s eta 0:01:49\n",
      "   - -------------------------------------- 3.9/124.9 MB 1.1 MB/s eta 0:01:52\n",
      "   - -------------------------------------- 4.2/124.9 MB 1.1 MB/s eta 0:01:50\n",
      "   - -------------------------------------- 4.5/124.9 MB 1.1 MB/s eta 0:01:49\n",
      "   - -------------------------------------- 4.7/124.9 MB 1.1 MB/s eta 0:01:48\n",
      "   - -------------------------------------- 5.0/124.9 MB 1.1 MB/s eta 0:01:47\n",
      "   - -------------------------------------- 5.2/124.9 MB 1.1 MB/s eta 0:01:46\n",
      "   - -------------------------------------- 5.5/124.9 MB 1.1 MB/s eta 0:01:47\n",
      "   - -------------------------------------- 5.5/124.9 MB 1.1 MB/s eta 0:01:47\n",
      "   - -------------------------------------- 5.8/124.9 MB 1.1 MB/s eta 0:01:48\n",
      "   - -------------------------------------- 6.0/124.9 MB 1.1 MB/s eta 0:01:47\n",
      "   - -------------------------------------- 6.0/124.9 MB 1.1 MB/s eta 0:01:47\n",
      "   -- ------------------------------------- 6.3/124.9 MB 1.1 MB/s eta 0:01:50\n",
      "   -- ------------------------------------- 6.3/124.9 MB 1.1 MB/s eta 0:01:50\n",
      "   -- ------------------------------------- 6.3/124.9 MB 1.1 MB/s eta 0:01:50\n",
      "   -- ------------------------------------- 6.6/124.9 MB 1.0 MB/s eta 0:01:58\n",
      "   -- ------------------------------------- 6.6/124.9 MB 1.0 MB/s eta 0:01:58\n",
      "   -- ------------------------------------- 6.8/124.9 MB 989.2 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.8/124.9 MB 989.2 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 6.8/124.9 MB 989.2 kB/s eta 0:02:00\n",
      "   -- ------------------------------------- 7.1/124.9 MB 934.0 kB/s eta 0:02:07\n",
      "   -- ------------------------------------- 7.3/124.9 MB 937.8 kB/s eta 0:02:06\n",
      "   -- ------------------------------------- 7.3/124.9 MB 937.8 kB/s eta 0:02:06\n",
      "   -- ------------------------------------- 7.6/124.9 MB 921.1 kB/s eta 0:02:08\n",
      "   -- ------------------------------------- 7.6/124.9 MB 921.1 kB/s eta 0:02:08\n",
      "   -- ------------------------------------- 7.9/124.9 MB 916.3 kB/s eta 0:02:08\n",
      "   -- ------------------------------------- 8.1/124.9 MB 913.5 kB/s eta 0:02:08\n",
      "   -- ------------------------------------- 8.1/124.9 MB 913.5 kB/s eta 0:02:08\n",
      "   -- ------------------------------------- 8.4/124.9 MB 907.7 kB/s eta 0:02:09\n",
      "   -- ------------------------------------- 8.7/124.9 MB 909.9 kB/s eta 0:02:08\n",
      "   -- ------------------------------------- 8.7/124.9 MB 909.9 kB/s eta 0:02:08\n",
      "   -- ------------------------------------- 8.7/124.9 MB 909.9 kB/s eta 0:02:08\n",
      "   -- ------------------------------------- 8.7/124.9 MB 909.9 kB/s eta 0:02:08\n",
      "   -- ------------------------------------- 8.9/124.9 MB 867.8 kB/s eta 0:02:14\n",
      "   -- ------------------------------------- 8.9/124.9 MB 867.8 kB/s eta 0:02:14\n",
      "   -- ------------------------------------- 9.2/124.9 MB 855.2 kB/s eta 0:02:16\n",
      "   -- ------------------------------------- 9.2/124.9 MB 855.2 kB/s eta 0:02:16\n",
      "   -- ------------------------------------- 9.2/124.9 MB 855.2 kB/s eta 0:02:16\n",
      "   --- ------------------------------------ 9.4/124.9 MB 833.0 kB/s eta 0:02:19\n",
      "   --- ------------------------------------ 9.7/124.9 MB 837.7 kB/s eta 0:02:18\n",
      "   --- ----------------------------------- 10.0/124.9 MB 841.2 kB/s eta 0:02:17\n",
      "   --- ----------------------------------- 10.2/124.9 MB 846.7 kB/s eta 0:02:16\n",
      "   --- ----------------------------------- 10.5/124.9 MB 848.6 kB/s eta 0:02:15\n",
      "   --- ----------------------------------- 10.5/124.9 MB 848.6 kB/s eta 0:02:15\n",
      "   --- ----------------------------------- 10.7/124.9 MB 843.1 kB/s eta 0:02:16\n",
      "   --- ----------------------------------- 11.0/124.9 MB 852.4 kB/s eta 0:02:14\n",
      "   --- ----------------------------------- 11.3/124.9 MB 856.2 kB/s eta 0:02:13\n",
      "   --- ----------------------------------- 11.5/124.9 MB 861.9 kB/s eta 0:02:12\n",
      "   --- ----------------------------------- 11.8/124.9 MB 868.5 kB/s eta 0:02:11\n",
      "   --- ----------------------------------- 12.1/124.9 MB 874.9 kB/s eta 0:02:09\n",
      "   --- ----------------------------------- 12.1/124.9 MB 874.9 kB/s eta 0:02:09\n",
      "   --- ----------------------------------- 12.3/124.9 MB 874.0 kB/s eta 0:02:09\n",
      "   --- ----------------------------------- 12.3/124.9 MB 874.0 kB/s eta 0:02:09\n",
      "   --- ----------------------------------- 12.6/124.9 MB 859.9 kB/s eta 0:02:11\n",
      "   --- ----------------------------------- 12.6/124.9 MB 859.9 kB/s eta 0:02:11\n",
      "   --- ----------------------------------- 12.6/124.9 MB 859.9 kB/s eta 0:02:11\n",
      "   ---- ---------------------------------- 12.8/124.9 MB 842.4 kB/s eta 0:02:14\n",
      "   ---- ---------------------------------- 13.1/124.9 MB 850.2 kB/s eta 0:02:12\n",
      "   ---- ---------------------------------- 13.4/124.9 MB 852.5 kB/s eta 0:02:11\n",
      "   ---- ---------------------------------- 13.4/124.9 MB 852.5 kB/s eta 0:02:11\n",
      "   ---- ---------------------------------- 13.9/124.9 MB 859.5 kB/s eta 0:02:10\n",
      "   ---- ---------------------------------- 14.2/124.9 MB 865.8 kB/s eta 0:02:08\n",
      "   ---- ---------------------------------- 14.2/124.9 MB 865.8 kB/s eta 0:02:08\n",
      "   ---- ---------------------------------- 14.2/124.9 MB 865.8 kB/s eta 0:02:08\n",
      "   ---- ---------------------------------- 14.2/124.9 MB 865.8 kB/s eta 0:02:08\n",
      "   ---- ---------------------------------- 14.4/124.9 MB 845.1 kB/s eta 0:02:11\n",
      "   ---- ---------------------------------- 14.4/124.9 MB 845.1 kB/s eta 0:02:11\n",
      "   ---- ---------------------------------- 14.4/124.9 MB 845.1 kB/s eta 0:02:11\n",
      "   ---- ---------------------------------- 14.7/124.9 MB 821.7 kB/s eta 0:02:15\n",
      "   ---- ---------------------------------- 14.9/124.9 MB 827.8 kB/s eta 0:02:13\n",
      "   ---- ---------------------------------- 14.9/124.9 MB 827.8 kB/s eta 0:02:13\n",
      "   ---- ---------------------------------- 15.2/124.9 MB 828.7 kB/s eta 0:02:13\n",
      "   ---- ---------------------------------- 15.5/124.9 MB 831.7 kB/s eta 0:02:12\n",
      "   ---- ---------------------------------- 15.7/124.9 MB 834.6 kB/s eta 0:02:11\n",
      "   ---- ---------------------------------- 15.7/124.9 MB 834.6 kB/s eta 0:02:11\n",
      "   ---- ---------------------------------- 16.0/124.9 MB 827.2 kB/s eta 0:02:12\n",
      "   ---- ---------------------------------- 16.0/124.9 MB 827.2 kB/s eta 0:02:12\n",
      "   ---- ---------------------------------- 16.0/124.9 MB 827.2 kB/s eta 0:02:12\n",
      "   ---- ---------------------------------- 16.0/124.9 MB 827.2 kB/s eta 0:02:12\n",
      "   ----- --------------------------------- 16.3/124.9 MB 807.7 kB/s eta 0:02:15\n",
      "   ----- --------------------------------- 16.3/124.9 MB 807.7 kB/s eta 0:02:15\n",
      "   ----- --------------------------------- 16.3/124.9 MB 807.7 kB/s eta 0:02:15\n",
      "   ----- --------------------------------- 16.5/124.9 MB 790.4 kB/s eta 0:02:18\n",
      "   ----- --------------------------------- 16.5/124.9 MB 790.4 kB/s eta 0:02:18\n",
      "   ----- --------------------------------- 16.8/124.9 MB 785.3 kB/s eta 0:02:18\n",
      "   ----- --------------------------------- 16.8/124.9 MB 785.3 kB/s eta 0:02:18\n",
      "   ----- --------------------------------- 16.8/124.9 MB 785.3 kB/s eta 0:02:18\n",
      "   ----- --------------------------------- 17.0/124.9 MB 774.7 kB/s eta 0:02:20\n",
      "   ----- --------------------------------- 17.0/124.9 MB 774.7 kB/s eta 0:02:20\n",
      "   ----- --------------------------------- 17.3/124.9 MB 777.3 kB/s eta 0:02:19\n",
      "   ----- --------------------------------- 17.6/124.9 MB 779.8 kB/s eta 0:02:18\n",
      "   ----- --------------------------------- 17.6/124.9 MB 779.8 kB/s eta 0:02:18\n",
      "   ----- --------------------------------- 17.6/124.9 MB 779.8 kB/s eta 0:02:18\n",
      "   ----- --------------------------------- 17.8/124.9 MB 769.4 kB/s eta 0:02:20\n",
      "   ----- --------------------------------- 17.8/124.9 MB 769.4 kB/s eta 0:02:20\n",
      "   ----- --------------------------------- 18.1/124.9 MB 768.3 kB/s eta 0:02:20\n",
      "   ----- --------------------------------- 18.4/124.9 MB 766.6 kB/s eta 0:02:19\n",
      "   ----- --------------------------------- 18.4/124.9 MB 766.6 kB/s eta 0:02:19\n",
      "   ----- --------------------------------- 18.4/124.9 MB 766.6 kB/s eta 0:02:19\n",
      "   ----- --------------------------------- 18.4/124.9 MB 766.6 kB/s eta 0:02:19\n",
      "   ----- --------------------------------- 18.6/124.9 MB 755.7 kB/s eta 0:02:21\n",
      "   ----- --------------------------------- 18.9/124.9 MB 759.2 kB/s eta 0:02:20\n",
      "   ----- --------------------------------- 18.9/124.9 MB 759.2 kB/s eta 0:02:20\n",
      "   ----- --------------------------------- 18.9/124.9 MB 759.2 kB/s eta 0:02:20\n",
      "   ----- --------------------------------- 19.1/124.9 MB 751.2 kB/s eta 0:02:21\n",
      "   ------ -------------------------------- 19.4/124.9 MB 752.8 kB/s eta 0:02:21\n",
      "   ------ -------------------------------- 19.4/124.9 MB 752.8 kB/s eta 0:02:21\n",
      "   ------ -------------------------------- 19.7/124.9 MB 751.5 kB/s eta 0:02:21\n",
      "   ------ -------------------------------- 19.9/124.9 MB 756.2 kB/s eta 0:02:19\n",
      "   ------ -------------------------------- 19.9/124.9 MB 756.2 kB/s eta 0:02:19\n",
      "   ------ -------------------------------- 20.2/124.9 MB 749.6 kB/s eta 0:02:20\n",
      "   ------ -------------------------------- 20.2/124.9 MB 749.6 kB/s eta 0:02:20\n",
      "   ------ -------------------------------- 20.4/124.9 MB 748.5 kB/s eta 0:02:20\n",
      "   ------ -------------------------------- 20.4/124.9 MB 748.5 kB/s eta 0:02:20\n",
      "   ------ -------------------------------- 20.7/124.9 MB 747.8 kB/s eta 0:02:20\n",
      "   ------ -------------------------------- 20.7/124.9 MB 747.8 kB/s eta 0:02:20\n",
      "   ------ -------------------------------- 20.7/124.9 MB 747.8 kB/s eta 0:02:20\n",
      "   ------ -------------------------------- 20.7/124.9 MB 747.8 kB/s eta 0:02:20\n",
      "   ------ -------------------------------- 20.7/124.9 MB 747.8 kB/s eta 0:02:20\n",
      "   ------ -------------------------------- 20.7/124.9 MB 747.8 kB/s eta 0:02:20\n",
      "   ------ -------------------------------- 20.7/124.9 MB 747.8 kB/s eta 0:02:20\n",
      "   ------ -------------------------------- 21.0/124.9 MB 718.0 kB/s eta 0:02:25\n",
      "   ------ -------------------------------- 21.0/124.9 MB 718.0 kB/s eta 0:02:25\n",
      "   ------ -------------------------------- 21.0/124.9 MB 718.0 kB/s eta 0:02:25\n",
      "   ------ -------------------------------- 21.0/124.9 MB 718.0 kB/s eta 0:02:25\n",
      "   ------ -------------------------------- 21.2/124.9 MB 707.9 kB/s eta 0:02:27\n",
      "   ------ -------------------------------- 21.2/124.9 MB 707.9 kB/s eta 0:02:27\n",
      "   ------ -------------------------------- 21.2/124.9 MB 707.9 kB/s eta 0:02:27\n",
      "   ------ -------------------------------- 21.2/124.9 MB 707.9 kB/s eta 0:02:27\n",
      "   ------ -------------------------------- 21.2/124.9 MB 707.9 kB/s eta 0:02:27\n",
      "   ------ -------------------------------- 21.2/124.9 MB 707.9 kB/s eta 0:02:27\n",
      "   ------ -------------------------------- 21.2/124.9 MB 707.9 kB/s eta 0:02:27\n",
      "   ------ -------------------------------- 21.2/124.9 MB 707.9 kB/s eta 0:02:27\n",
      "   ------ -------------------------------- 21.2/124.9 MB 707.9 kB/s eta 0:02:27\n",
      "   ------ -------------------------------- 21.5/124.9 MB 648.0 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.5/124.9 MB 648.0 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n",
      "   ------ -------------------------------- 21.8/124.9 MB 647.6 kB/s eta 0:02:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\http\\client.py\", line 458, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\http\\client.py\", line 502, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 379, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 554, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 469, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 184, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 55, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 65, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\Users\\Administrator\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets build the XGBoost to build the model that accurately classifies the wine quality based on the the wine features\n",
    "\n",
    "# here we instantiate the XGBoostClassifier then fit to the X train and the y train le (labelEncoded)\n",
    "xgb_clf = XGBClassifier().fit(X_train, y_train_le)\n",
    "\n",
    "# lets make predictions on the training amd test set\n",
    "training_preds = xgb_clf.predict(X_train)\n",
    "test_preds = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 100.0%\n",
      "Testing (validation) accuracy:68.0%\n"
     ]
    }
   ],
   "source": [
    "# determine the performance of the model\n",
    "training_accuracy = accuracy_score(y_train_le, training_preds)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test_le, test_preds)\n",
    "\n",
    "print(\"Training accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Testing (validation) accuracy:{:.4}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate XGBClassifier\n",
    "# clf = XGBClassifier()\n",
    "\n",
    "# # Fit XGBClassifier\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on training and test sets\n",
    "# training_preds = clf.predict(X_train)\n",
    "# test_preds = clf.predict(X_test)\n",
    "\n",
    "# # Accuracy of training and test sets\n",
    "# training_accuracy = accuracy_score(y_train, training_preds)\n",
    "# test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "# print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n",
    "# print('Validation accuracy: {:.4}%'.format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy: 100.0%\n",
    "# Testing (validation) accuracy:68.0%\n",
    "\n",
    "# the performance of the xgboost algorithm is a clear indication of overfitting\n",
    "# the model learned the training data including its noise..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning XGBoost\n",
    "\n",
    "The model had a somewhat lackluster performance on the test set compared to the training set, suggesting the model is beginning to overfit to the training data. Let's tune the model to increase the model performance and prevent overfitting. \n",
    "\n",
    "You've already encountered a lot of parameters when working with Decision Trees, Random Forests, and Gradient Boosted Trees.\n",
    "\n",
    "For a full list of model parameters, see the [XGBoost Documentation](http://xgboost.readthedocs.io/en/latest/parameter.html).\n",
    "\n",
    "Examine the tunable parameters for XGboost, and then fill in appropriate values for the `param_grid` dictionary in the cell below. \n",
    "\n",
    "**_NOTE:_** Remember, `GridSearchCV` finds the optimal combination of parameters through an exhaustive combinatoric search.  If you search through too many parameters, the model will take forever to run! To ensure your code runs in sufficient time, we restricted the number of values the parameters can take.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'max_depth': [6],\n",
    "    'min_child_weight': [1, 2],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'n_estimators': [100],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have constructed our `params` dictionary, create a `GridSearchCV` object in the cell below and use it to iteratively tune our XGBoost model.  \n",
    "\n",
    "Now, in the cell below:\n",
    "\n",
    "* Create a `GridSearchCV` object. Pass in the following parameters:\n",
    "    * `clf`, the classifier\n",
    "    * `param_grid`, the dictionary of parameters we're going to grid search through\n",
    "    * `scoring='accuracy'`\n",
    "    * `cv=None`\n",
    "    * `n_jobs=1`\n",
    "* Fit our `grid_clf` object and pass in `X_train` and `y_train`\n",
    "* Store the best parameter combination found by the grid search in `best_parameters`. You can find these inside the grid search object's `.best_params_` attribute \n",
    "* Use `grid_clf` to create predictions for the training and test sets, and store them in separate variables \n",
    "* Compute the accuracy score for the training and test predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Grid Search found the following optimal parameters: \n",
      "learning_rate:0.1\n",
      "max_depth:6\n",
      "min_child_weight:1\n",
      "n_estimators:100\n",
      "subsample:0.7\n",
      "The Training Accuracy: 99.83%\n",
      "The Validation Accuracy: 68.25%\n"
     ]
    }
   ],
   "source": [
    "grid_clf = GridSearchCV(xgb_clf, param_grid, scoring = 'accuracy', cv = None, n_jobs = 1)\n",
    "grid_clf.fit(X_train, y_train_le)\n",
    "\n",
    "# find the best parameters..\n",
    "best_parameters = grid_clf.best_params_\n",
    "\n",
    "print(\"The Grid Search found the following optimal parameters: \")\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print('%s:%r'%(param_name, best_parameters[param_name]))\n",
    "    \n",
    "training_preds =  grid_clf.predict(X_train)\n",
    "testing_preds = grid_clf.predict(X_test)\n",
    "\n",
    "training_accuracy = accuracy_score(y_train_le, training_preds)\n",
    "test_accuracy = accuracy_score(y_test_le, testing_preds)\n",
    "\n",
    "print(\"The Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"The Validation Accuracy: {:.4}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_clf = GridSearchCV(clf, param_grid, scoring = \"accuracy\", cv = None, n_jobs = 1)\n",
    "# grid_clf.fit(X_train, y_train)\n",
    "\n",
    "# best_parameters = grid_clf.best_params_\n",
    "\n",
    "# print('Grid Search found the following optimal parameters: ')\n",
    "# for param_name in sorted(best_parameters.keys()):\n",
    "#     print('%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# training_preds = grid_clf.predict(X_train)\n",
    "# test_preds = grid_clf.predict(X_test)\n",
    "# training_accuracy = accuracy_score(y_train, training_preds)\n",
    "# test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "# print('')\n",
    "# print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n",
    "# print('Validation accuracy: {:.4}%'.format(test_accuracy * 100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Great! You've now successfully made use of one of the most powerful boosting models in data science for modeling.  We've also learned how to tune the model for better performance using the grid search methodology we learned previously. XGBoost is a powerful modeling tool to have in your arsenal. Don't be afraid to experiment with it! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
